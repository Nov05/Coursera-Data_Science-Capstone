---
title: "Capstone Week 3 Quiz"
author: "Wenjing Liu"
date: "January 23, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br><br><br>

## Quiz 2: Natural language processing I

Data Science Capstone: https://www.coursera.org/learn/data-science-project/  
Quiz: https://www.coursera.org/learn/data-science-project/exam/QbBvW/quiz-2-natural-language-processing-i

Note: For how to develop text input prediction models, refer to this report http://rpubs.com/Nov05/459931, in which only Twitter text was explored. However, for actual models, I might use all the English text files, e.g. Twitter, blogs and news, or at least a sample of text of all the files. Also, in the coming weeks, for the actual product I will reduce the N-gram dictionary size to improve the performance, or use lemmatization and/or stemming to push it further.

N-gram Modeling With Markov Chains  
https://sookocheff.com/post/nlp/ngram-modeling-with-markov-chains/

### For each of the sentence fragments below use your natural language processing algorithm to predict the next word in the sentence.

```{r message=FALSE, warning=FALSE}
library(tm)

# constants
co_text_attr_en = "D:/R/data/capstone/text_attr_en.rds"
co_tidy_twitter_en = "D:/R/data/capstone/tidy_twitter_en.rds"
co_tidy_nostop_twitter_en = "D:/R/data/capstone/tidy_nostop_twitter_en.rds"
co_1gram_twitter_en = "D:/R/data/capstone/1gram_twitter_en.rds"
co_2gram_twitter_en = "D:/R/data/capstone/2gram_twitter_en.rds"
co_3gram_twitter_en = "D:/R/data/capstone/3gram_twitter_en.rds"
co_1gram_nostop_twitter_en = "D:/R/data/capstone/1gram_nostop_twitter_en.rds"
co_2gram_nostop_twitter_en = "D:/R/data/capstone/2gram_nostop_twitter_en.rds"
co_3gram_nostop_twitter_en = "D:/R/data/capstone/3gram_nostop_twitter_en.rds"

df <- readRDS(co_3gram_twitter_en)
df_nostop <- readRDS(co_3gram_nostop_twitter_en)
```

**1. The guy in front of me just bought a pound of bacon, a bouquet, and a case of**

Options: prezels, soda, beer, cheese

**Answer: beer**

```{r message=FALSE, warning=FALSE}
head(df[grep("^case of", df[,1]),], 10)
```

**2. You're the reason why I smile everyday. Can you follow me please? It would mean the**

Options: world, best, most, universe

**Answer: world**

```{r message=FALSE, warning=FALSE}
head(df[grep("^mean the ", df[,1]),], 10)
```

**3. Hey sunshine, can you follow me and make me the**

Options: bluest, smelliest, saddest, happiest

**Answer: happiest**

Note: The top frequence of the 3-grams is "me the f*ck". Interesting. Probably need to add the f-word to stop word list? Lol.

```{r message=FALSE, warning=FALSE}
head(df[grep("^me the", df[,1]),], 10)
```

**4. Very early observations on the Bills game: Offence still struggling but the**

Options: crowd, defense, referees, players(wrong)

**Answer: defense**

Note: It didn't match anything in the options by using Twitter N-gram dictionary. Probably need to use models generated by all the English files.

```{r message=FALSE, warning=FALSE}
head(df[grep("^struggling but", df[,1]),], 10) # It didn't match anything in the options.
str <- "Very early observations on the Bills game: Offence still struggling but the"
str <- removeWords(str, stopwords("en")); str <- gsub("\\s+", " ", str); str
head(df_nostop[grep("^still struggling", df_nostop[,1]),], 10)
rbind(df_nostop[grep("^still struggling crowd", df_nostop[,1]),], 
      df_nostop[grep("^still struggling defense", df_nostop[,1]),],
      df_nostop[grep("^still struggling referees", df_nostop[,1]),],
      df_nostop[grep("^still struggling players", df_nostop[,1]),])
```

**5. Go on a romantic date at the**

Options: mall, grocery(wrong), movies, beach

**Answer: beach**

Note: Should consider sentiments?

```{r}
head(df[grep("^date at", df[,1]),], 10)
```

```{r message=FALSE, warning=FALSE}
head(df_nostop[grep("^romantic date", df_nostop[,1]),], 10)
head(df[grep("^date at", df[,1]),], 10) # The only match was "date atl interview"
rbind(df[grep("date at mall", df[,1]),], 
      df[grep("date at grocery", df[,1]),],
      df[grep("date at movies", df[,1]),], 
      df[grep("date at beach", df[,1]),])
rbind(df_nostop[grep("date mall", df_nostop[,1]),], 
      df_nostop[grep("date grocery", df_nostop[,1]),],
      df_nostop[grep("date movies", df_nostop[,1]),], # "third-wheel date movies"
      df_nostop[grep("date beach", df_nostop[,1]),]) # "asked date beach"
```

**6. Well I'm pretty sure my granny has some old bagpipes in her garage I'll dust them oô€ƒ— and be on my**

Options: way, horse, motorcycle, phone

**Answer: way**

```{r}
head(df[grep("^on my ", df[,1]),], 10)
```

**7. Ohhhhh #PointBreak is on tomorrow. Love that film and haven't seen it in quite some**

Options: thing, weeks, time, years

**Answer: time**

```{r}
head(df[grep("^quite some ", df[,1]),], 10)
```

**8. After the ice bucket challenge Louis will push his long wet hair out of his eyes with his little**

Options: fingers, eyes, ears, toes

**Answer: fingers**

```{r}
head(df[grep("^his little ", df[,1]),], 10)
str <- "After the ice bucket challenge Louis will push his long wet hair out of his eyes with his little"
str <- removeWords(str, stopwords("en")); str <- gsub("\\s+", " ", str); str
head(df_nostop[grep("^eyes little ", df_nostop[,1]),], 10)
rbind(df[grep("his little fingers", df[,1]),], 
      df[grep("his little eyes", df[,1]),],
      df[grep("his little ears", df[,1]),], 
      df[grep("his little toes", df[,1]),])
rbind(df[grep("his little finger", df[,1]),], 
      df[grep("his little eye", df[,1]),],
      df[grep("his little ear", df[,1]),], 
      df[grep("his little toe", df[,1]),])
```

**9. Be grateful for the good times and keep the faith during the**

Options: worse, bad, hard, sad

**Answer: bad**

```{r}
head(df[grep("^during the ", df[,1]),], 10)
head(df_nostop[grep("^faith during ", df_nostop[,1]),], 10)
rbind(df[grep("during the worse", df[,1]),], 
      df[grep("during the bad", df[,1]),],
      df[grep("during the hard", df[,1]),], 
      df[grep("during the sad", df[,1]),])
```

**10. If this isn't the cutest thing you've ever seen, then you must be**

Options: asleep, insensitive, callous, insane

**Answer: insane**

```{r}
head(df[grep("^must be ", df[,1]),], 10)
str <- "If this isn't the cutest thing you've ever seen, then you must be"
str <- removeWords(str, stopwords("en")); str <- gsub("\\s+", " ", str); str
head(df_nostop[grep("^seen must ", df_nostop[,1]),], 10) # seen must keep
rbind(df[grep("must be asleep", df[,1]),], 
      df[grep("must be insensitive", df[,1]),],
      df[grep("must be callous", df[,1]),], 
      df[grep("must be insane", df[,1]),])
```

<br><br><br>

Refence report:  
http://rstudio-pubs-static.s3.amazonaws.com/387645_d494b67fb45e4d3792fb679eb274291c.html  
https://rpubs.com/redneckz/smart-keyboard-basic-modeling